{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North Atlantic Right Whale detector-part 1\n",
    "\n",
    "This is the first of a two parts tutorial illustrating how to build a deep learning acoustic detector with ketos.\n",
    "\n",
    "We'll use the database built in the [Creating a training database](https://docs.meridian.cs.dal.ca/ketos/tutorials/create_database_simpler/index.html) tutorial, in which we converted raw audio files to spectrograms of the North Atlantic Right Whale's stereotypical upcall.\n",
    "If you didn't follow that tutorial, you can find the resulting database in the .zip file linked at the top of this page. There you will also find an executable version of this jupyter notebook, in case you want to follow along.\n",
    "\n",
    "Our final goal is to have a detector that can take a long .wav file (e.g.: 30 min) and tell us where within that file are the right whales upcalls.\n",
    "\n",
    "The core part of such detector will be a binary classifer that takes 3-s long spectrograms and classifies them into \"contains an upcall\" or \"does not contain an upcall\". We will treat these two classes as \"1\" and \"0\". This is what we'll cover in this tutorial.\n",
    "\n",
    "The [second part](https://docs.meridian.cs.dal.ca/ketos/tutorials/create_a_narw_detector/index.html) will take this binary classifier and turn it into a detector.\n",
    "\n",
    "## Contents:\n",
    "\n",
    "[1. Importing the packages](#section1)  \n",
    "[2. Creating the data feed](#section2)  \n",
    "[3. Creating and training the Neural Network](#section3)  \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below define the random seeds used in the tutorial. This is necessary to ensure that you get the precisely the same results every time you run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2000)\n",
    "\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the packages\n",
    "We start by importing the ketos modules and classes we will use throughout the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BatchGenerator in module ketos.data_handling.data_feeding:\n",
      "\n",
      "class BatchGenerator(builtins.object)\n",
      " |  BatchGenerator(batch_size, data_table=None, annot_in_data_table=True, annot_table=None, x=None, y=None, select_indices=None, output_transform_func=None, map_labels=True, x_field='data', y_field='label', shuffle=False, refresh_on_epoch_end=False, return_batch_ids=False, filter=None, n_extend=0)\n",
      " |  \n",
      " |  Creates batches to be fed to a model\n",
      " |  \n",
      " |  Instances of this class are python generators. They will load one batch at \n",
      " |  a time from a HDF5 database, which is particularly useful when working with \n",
      " |  larger than memory datasets.\n",
      " |  \n",
      " |  It is also possible to load the entire data set into memory and provide it \n",
      " |  to the BatchGenerator via the arguments x and y. This can be convenient when \n",
      " |  working with smaller data sets.\n",
      " |  \n",
      " |  Yields:\n",
      " |  (X,Y) or (ids,X,Y) if 'return_batch_ids' is True.\n",
      " |  \n",
      " |      X is a batch of data in the form of an np.array of shape (batch_size,mx,nx) where \n",
      " |      mx,nx are the shape of one instance of X in the database. The number\n",
      " |      of dimensions in addition to 'batch_size' will not necessarily be 2, but correspond to\n",
      " |      the instance shape (1 for 1d instances, 3 for 3d, etc).\n",
      " |  \n",
      " |      It is also possible to load multiple data objects per instance by specifying multiple x_field \n",
      " |      values, e.g., 'x_field=['spectrogram', 'waveform']'. In such cases, the return argument X is a \n",
      " |      np.array with shape (batch_size,) and each element is a np.void array with length equal to the \n",
      " |      number of x fields. Each element in this array is a np.array and can be accessed either through \n",
      " |      use of integer indices or the x_field names, e.g., the first spectrogram in the batch can be \n",
      " |      accessed as X[0][0] or X[0]['spectrogram'].\n",
      " |  \n",
      " |      Similarly, Y is an np.array of shape(batch_size) with the corresponding labels.\n",
      " |      Each item in the array is a named array of shape=(n_fields), where n_field is the number of fields\n",
      " |      specified in the 'y_field' argument. For instance, if 'y_field'=['label', 'start', 'end'], you can access\n",
      " |      the first label with Y[0]['label'].\n",
      " |      Notice that even if y_field==['label'], you would still use the Y[0]['label'] syntax.\n",
      " |  \n",
      " |      Important note: The above remarks regarding the shapes of X and Y assume that the output \n",
      " |      transform function `output_transform_func` only modifies the contents and not the shapes \n",
      " |      of X and Y, which may not always be the case.\n",
      " |  \n",
      " |  Args:\n",
      " |      batch_size: int\n",
      " |          The number of instances in each batch. The last batch of an epoch might \n",
      " |          have fewer examples, depending on the number of instances in the hdf5_table.\n",
      " |          If the batch size is greater than the number of instances available, batch_size will \n",
      " |          be set to the number of instances. and a warning will be issued\n",
      " |      data_table: pytables table (instance of table.Table()) \n",
      " |          The HDF5 table containing the data\n",
      " |      annot_in_data_table: bool\n",
      " |          Whether or not the annotation fields (e.g.: 'label') is in the data_table (True, default) or in a separate annot_table (False).\n",
      " |      annot_table: pytables table (instance of table.Table()) \n",
      " |          A separate table for the annotations(labels), in case they are not included as fields in the data_table.\n",
      " |          This table must have a 'data_index' field, which corresponds to the the index (row number) of the data instance in the data_tables.\n",
      " |          Usually, a separete table will be used when the data is strongly annotated (i.e.: possibily more than one annotation per data instance).\n",
      " |          When there is only one annotation for each data instance, it's recommended that annotations are included in the data_table for performance gains.\n",
      " |      x: numpy array\n",
      " |          Array containing the data images.\n",
      " |      y: numpy array\n",
      " |          Array containing the data labels. \n",
      " |          This array is expected to have a one-to-one correspondence to the x array (i.e.: y[0] is expected to have the label for x[0], y[1] for x[1], etc).\n",
      " |          If there are multiple labels for each data instance in x, use a data_table and an annot_table instead.\n",
      " |      select_indices: list of ints\n",
      " |          Indices of those instances that will retrieved from the HDF5 table by the \n",
      " |          BatchGenerator. By default all instances are retrieved.\n",
      " |      output_transform_func: function\n",
      " |          A function to be applied to the batch, transforming the instances. Must accept \n",
      " |          'X' and 'Y' and, after processing, also return  'X' and 'Y' in a tuple.\n",
      " |      map_labels: bool\n",
      " |          If True, maps all labels to integers 0,1,2,3... Ketos neural networks expect labels to be incremental and starting from 0. \n",
      " |          Default is True. Note: If more than one field is specified in the `y_field` argument, the mapping will only be applied to \n",
      " |          the first field.\n",
      " |      x_field: str\n",
      " |          The name of the column containing the X data in the hdf5_table\n",
      " |      y_field: str\n",
      " |          The name of the column containing the Y labels in the hdf5_table\n",
      " |      shuffle: bool\n",
      " |          If True, instances are selected randomly (without replacement). If False, \n",
      " |          instances are selected in the order the appear in the database\n",
      " |      refresh_on_epoch_end: bool\n",
      " |          If True, and shuffle is also True, resampling is performed at the end of \n",
      " |          each epoch resulting in different batches for every epoch. If False, the \n",
      " |          same batches are used in all epochs.\n",
      " |          Has no effect if shuffle is False.\n",
      " |      return_batch_ids: bool\n",
      " |          If False, each batch will consist of X and Y. If True, the instance indices \n",
      " |          (as they are in the hdf5_table) will be included ((ids, X, Y)).\n",
      " |      filter: str\n",
      " |          A valid PyTables query. If provided, the Batch Generator will query the hdf5\n",
      " |          database before defining the batches and only the matching records will be used.\n",
      " |          Only relevant when data is passed through the hdf5_table argument. If both 'filter'\n",
      " |          and 'indices' are passed, 'indices' is ignored.\n",
      " |      n_extend: int\n",
      " |          Extend every batch by including the last n_extend samples from \n",
      " |          the previous batch and the first n_extend samples from the following batch.\n",
      " |          The first batch is only extended at the end, while the last batch is only \n",
      " |          extended at the beginning. The default value is zero, i.e., no extension.  \n",
      " |  \n",
      " |  Attr:\n",
      " |      data: pytables table (instance of table.Table()) \n",
      " |          The HDF5 table containing the data\n",
      " |      n_instances: int\n",
      " |          The number of intances (rows) in the hdf5_table\n",
      " |      n_batches: int\n",
      " |          The number of batches of size 'batch_size' for each epoch\n",
      " |      entry_indices:list of ints\n",
      " |          A list of all intance indices, in the order used to generate batches for this epoch\n",
      " |      batch_indices: list of tuples (int,int)\n",
      " |          A list of (start,end) indices for each batch. These indices refer to the 'entry_indices' attribute.\n",
      " |      batch_count: int\n",
      " |          The current batch within the epoch. This will be the batch yielded on the next call to 'next()'.\n",
      " |      from_memory: bool\n",
      " |          True if the data are loaded from memory rather than an HDF5 table.\n",
      " |  \n",
      " |  Examples:\n",
      " |      >>> from tables import open_file\n",
      " |      >>> from ketos.data_handling.database_interface import open_table\n",
      " |      >>> h5 = open_file(\"ketos/tests/assets/11x_same_spec.h5\", 'r') # create the database handle  \n",
      " |      >>> data_table = open_table(h5, \"/group_1/table_data\")\n",
      " |      >>> annot_table = open_table(h5, \"/group_1/table_annot\")\n",
      " |      >>> #Create a BatchGenerator from a data_table and separate annotations in a anot_table\n",
      " |      >>> train_generator = BatchGenerator(data_table=data_table, annot_in_data_table=False, annot_table=annot_table, batch_size=3, x_field='data', return_batch_ids=True, map_labels=True) #create a batch generator \n",
      " |      >>> #Run 2 epochs. \n",
      " |      >>> n_epochs = 2    \n",
      " |      >>> for e in range(n_epochs):\n",
      " |      ...    for batch_num in range(train_generator.n_batches):\n",
      " |      ...        ids, batch_X, batch_Y = next(train_generator)\n",
      " |      ...        print(\"epoch:{0}, batch {1} | instance ids:{2}, X batch shape: {3} labels for instance {4}: {5}\".format(e, batch_num, ids, batch_X.shape, ids[0], batch_Y[0]))\n",
      " |      epoch:0, batch 0 | instance ids:[0, 1, 2], X batch shape: (3, 12, 12) labels for instance 0: [0, 1]\n",
      " |      epoch:0, batch 1 | instance ids:[3, 4, 5], X batch shape: (3, 12, 12) labels for instance 3: [0, 1]\n",
      " |      epoch:0, batch 2 | instance ids:[6, 7, 8, 9, 10], X batch shape: (5, 12, 12) labels for instance 6: [0, 1]\n",
      " |      epoch:1, batch 0 | instance ids:[0, 1, 2], X batch shape: (3, 12, 12) labels for instance 0: [0, 1]\n",
      " |      epoch:1, batch 1 | instance ids:[3, 4, 5], X batch shape: (3, 12, 12) labels for instance 3: [0, 1]\n",
      " |      epoch:1, batch 2 | instance ids:[6, 7, 8, 9, 10], X batch shape: (5, 12, 12) labels for instance 6: [0, 1]\n",
      " |      >>> h5.close() #close the database handle.\n",
      " |      >>> # Creating a Batch Generator from a data tables that includes annotations\n",
      " |      >>> h5 = open_file(\"ketos/tests/assets/mini_narw.h5\", 'r') # create the database handle  \n",
      " |      >>> data_table = open_table(h5, \"/train/data\")\n",
      " |      >>> #Applying a custom function to the batch\n",
      " |      >>> #Takes the mean of each instance in X; leaves Y untouched\n",
      " |      >>> def apply_to_batch(X,Y):\n",
      " |      ...    X = np.mean(X, axis=(1,2)) #since X is a 3d array\n",
      " |      ...    return (X,Y)\n",
      " |      >>> train_generator = BatchGenerator(data_table=data_table, batch_size=3, annot_in_data_table=True, return_batch_ids=False, output_transform_func=apply_to_batch) \n",
      " |      >>> X,Y = next(train_generator)                \n",
      " |      >>> #Now each X instance is one single number, instead of a 2d array\n",
      " |      >>> #A batch of size 3 is an array of the 3 means\n",
      " |      >>> X.shape\n",
      " |      (3,)\n",
      " |      >>> #Here is how one X instance looks like\n",
      " |      >>> X[0]\n",
      " |      -37.247124\n",
      " |      >>> #Y is the same as before \n",
      " |      >>> Y.shape\n",
      " |      (3,)\n",
      " |      >>> h5.close()\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __create_batches__(self, n_ext=0)\n",
      " |      Prepare batches.\n",
      " |      \n",
      " |      Divides the indices into batches of self.batch_size, based on the list generated \n",
      " |      by `update_indices()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          n_ext: int\n",
      " |              Extend every batch by including the last n_extend samples from \n",
      " |              the previous batch and the first n_extend samples from the following batch.\n",
      " |              The first batch is only extended at the end, while the last batch is only \n",
      " |              extended at the beginning. The default value is zero, i.e., no extension.  \n",
      " |      \n",
      " |      Returns:\n",
      " |          list_of_indices: list of tuples\n",
      " |              A list of tuple, each containing two integer values: the start and end of the batch. \n",
      " |              These positions refer to the list stored in self.entry_indices.\n",
      " |  \n",
      " |  __create_label_mapping__(self, unique_labels)\n",
      " |      Create mapping that maps the original labels to incremental integer values starting from 0.\n",
      " |      \n",
      " |      E.g. a dataset with labels 2,3,5 will be mapped to 0,1,2\n",
      " |      \n",
      " |      Args:\n",
      " |          unique_labels: numpy array\n",
      " |              Unique labels\n",
      " |  \n",
      " |  __init__(self, batch_size, data_table=None, annot_in_data_table=True, annot_table=None, x=None, y=None, select_indices=None, output_transform_func=None, map_labels=True, x_field='data', y_field='label', shuffle=False, refresh_on_epoch_end=False, return_batch_ids=False, filter=None, n_extend=0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __next__(self)\n",
      " |      Return: tuple\n",
      " |      A batch of instances (X,Y) or, if 'returns_batch_ids\" is True, a batch of instances accompanied by their indices (ids, X, Y)\n",
      " |  \n",
      " |  __update_indices__(self, indices=None)\n",
      " |      Updates the indices used to divide the instances into batches.\n",
      " |      \n",
      " |      A list of indices is kept in the self.data_indices attribute.\n",
      " |      The order of the indices determines which instances will be placed in each batch.\n",
      " |      If the self.shuffle is True, the indices are randomly reorganized, resulting in \n",
      " |      batches with randomly selected instances.\n",
      " |  \n",
      " |  apply_label_mapping(self, mapper)\n",
      " |      Map the original labels to a new set of labels\n",
      " |      \n",
      " |      Args:\n",
      " |          mapper: dict\n",
      " |              A dictionary that maps each of the original labels to a new label\n",
      " |  \n",
      " |  get_indices(self)\n",
      " |      Get the indice sequence used for sampling the data table\n",
      " |      \n",
      " |      Returns:\n",
      " |          : array\n",
      " |              Indices\n",
      " |  \n",
      " |  get_samples(self, indices, annot_indices=None)\n",
      " |      Get data samples for specified indices\n",
      " |      \n",
      " |      Args:\n",
      " |          indices: list of ints\n",
      " |              Row indices of the samples in the data table\n",
      " |          annot_indices: list of ints\n",
      " |              Row indices of the matching samples in the annotation table, if applicable.\n",
      " |      \n",
      " |      Returns: \n",
      " |          : tuple\n",
      " |              A batch of instances (X,Y)\n",
      " |  \n",
      " |  get_unique_labels(self, check_attr=True)\n",
      " |      Get a list of the labels occurring in the dataset.\n",
      " |      \n",
      " |      If check_attr=True, the method first checks if the table has an attribute named \n",
      " |      'unique_labels'. If the attribute is present, the method simply returns its value.\n",
      " |      \n",
      " |      If the attibute is not found (or check_attr=False), the method goes through every \n",
      " |      instance in the dataset to identify the unique labels. \n",
      " |      OBS: If more than one field was specified in the `y_field` argument, the method \n",
      " |      will consider only the first field when determining the unique labels.\n",
      " |      \n",
      " |      The unique labels are stored as a class attribute. Therefore, while the first \n",
      " |      call of the method may be slow, subsequent calls will be very fast as the \n",
      " |      method will simply return the class attribute value. \n",
      " |      \n",
      " |      Args: \n",
      " |          check_attr: bool\n",
      " |              Check if the table has an attribute named 'unique_labels' and return its \n",
      " |              value, if found.\n",
      " |      \n",
      " |      Returns:\n",
      " |          unique_labels: numpy array\n",
      " |              List of unique labels in the dataset.\n",
      " |  \n",
      " |  reset(self, indices=None)\n",
      " |      Reset the batch generator.\n",
      " |      \n",
      " |      Resets the batch index counter and reshuffles the sample indices \n",
      " |      if shuffle was set to True.\n",
      " |      \n",
      " |      Args:\n",
      " |          indices: array\n",
      " |              Manually specify the sequence of indices that should be used \n",
      " |              after reset.\n",
      " |  \n",
      " |  set_return_batch_ids(self, v)\n",
      " |      Change the behaviour of the generator between returning\n",
      " |      only X,Y or id,X,Y\n",
      " |      \n",
      " |      Args:\n",
      " |          v: bool\n",
      " |              Whether to return id in addition to X,Y\n",
      " |  \n",
      " |  set_shuffle(self, v)\n",
      " |      Change the behaviour of the generator between shuffling or not \n",
      " |      shuffling the indices.\n",
      " |      \n",
      " |      Args:\n",
      " |          v: bool\n",
      " |              Whether to return shuffle the indices\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ketos.data_handling.database_interface as dbi\n",
    "from ketos.neural_networks.resnet import ResNetInterface\n",
    "from ketos.data_handling.data_feeding import BatchGenerator\n",
    "\n",
    "help(BatchGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating the data feed\n",
    "\n",
    "The database created in the [Creating a training database](#) tutorial organizes the data into \"train\" and \"validation\". Ketos' ``BatchGenerator`` provides an interface that makes it easy to use this database during the training process. It selects batches of data from the database and feeds it to the neural network. We are dealing with small amounts of data for the purposes of this tutorial, but this is very helpful when dealing with larger databases, which is often the case in deep learning.\n",
    "\n",
    "First, we open a connection to our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db = dbi.open_file(\"database.h5\", 'r')\n",
    "db = dbi.open_file(\"C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\CompletedModels\\\\20230524_01\\\\databaseMinkeTrimmed01.h5\", 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to open the tables containing the spectrograms and annotations. All we are doing here is creating a handle to indicate where the BatchGenerator can find the spectrograms and annotations, but no data is actually loaded into memory at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dbi.open_table(db, \"/train/data\")\n",
    "val_data = dbi.open_table(db, \"/val/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the handles ready, we can create the two batch generators, one to load training data and another for the validation data.\n",
    "\n",
    "There are a few options we need to configure:  \n",
    "**batch_size** indicates how many data samples (spectrograms) will be loaded into memory at a time\n",
    "\n",
    "**data_table**  indicates the table handle we just created  \n",
    "\n",
    "**output_transform_func** indicates a function that transforms the data as it is loaded into memory. This can be any python function. To make the job easier, the neural network architectures availablable in ketos all have an interface that includes a transformation function to put the data into the right format for that type of neural network  \n",
    "\n",
    "**shuffle** indicates whether we want to shuffle the data before creating the batches. That's a good idea for our case because in the database our spectrograms are sorted by labels (all the 'upcalls' followed by all 'backgrounds'), but we want each batch to contain a mix\n",
    "\n",
    "**refresh_on_epoch_end** When we train the neural network, we will show it the whole training dataset several times (each time is called an 'epoch'). Setting this option to ```True``` makes the batch generator reshuffle the data at the end of each epoch, so that the batches contain different examples each time.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is an example of a simple data transformation function\n",
    "# (However, in this tutorial we will use the ResNetInterface.transform_batch function provided by Ketos)\n",
    "def transform_batch(X, Y):\n",
    "  x = X.reshape(X.shape[0],X.shape[1],X.shape[2],1)\n",
    "  y = tf.one_hot(Y['label'], depth=2, axis=1).numpy()\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = BatchGenerator(batch_size=128, data_table=train_data, \n",
    "                                  output_transform_func=ResNetInterface.transform_batch,\n",
    "                                  shuffle=True, refresh_on_epoch_end=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the validation generator, we'll just change the table handles. We'll also set set refresh_on_epoch_end to ```False```, so that the validation set is shuffled once before creating the batches for the first epoch but not in susequent epochs. This way, everytime we validate the models (i.e.: at the end of each training epoch) it will use the same order for the validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = BatchGenerator(batch_size=128, data_table=val_data,\n",
    "                                 output_transform_func=ResNetInterface.transform_batch,\n",
    "                                 shuffle=True, refresh_on_epoch_end=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and training the neural network\n",
    "\n",
    "For this exercise we will use a ResNet-like architecture, which is a popular architecture for image recognition and has also shown good results for audio recognition using spectral inputs.\n",
    "\n",
    "Ketos' Neural Network interfaces can use *recipes* to create a network. The recipe files are an easy way to let others reproduce the architecture you used. You can find a *recipe.json* file within the .zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNetInterface.build_from_recipe_file(\n",
    "    Path('C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\CompletedModels\\\\20230524_01\\\\recipe.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this creates a brand new network. That's what we want since we are training from scratch, but once the model is trained, we can also save it for later use and share it with others. That saved model will not only contain the recipe for recreating the architecture, but also the weights optimized (or learned) during the training process and can, therefore, be used without the need for training again (or access to the training data).\n",
    "\n",
    "Before we start training, we just need to connect the batch generators we created to the network interface, so it can access the data as it needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.train_generator = train_generator\n",
    "resnet.val_generator = val_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set where we want to save our model's checkpoints. By default, ketos will save the model progress every 5 epochs (this can be adjusted by the checkpoint_freq parameter in the train_loop method, but we'll use the default). If the folder does not yet exist, Ketos will create it. Later when we save the model, Ketos will take the latest checkpoint and include it in the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.checkpoint_dir = \"C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\CompletedModels\\\\20230524_01\\\\Checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our upcall/background classifier by calling the *train_loop* method in our resnet object. In the example below, we specify the number of epochs, which indicates how many times the network will go through the training dataset in order to learn usefull features for classification. We also set the verbose parameter to ``True``, which will print some summary metrics during the training.\n",
    "\n",
    "Given the simple task/database we are using for this tutorial, 30 epochs should give us a reasonably good classifier to build a detector in part 2. If you are following along, please notice that it might take a while, depending on your computer (about 60 min on an average laptop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "Epoch: 1 \n",
      "train_loss: 0.16833868622779846\n",
      "train_CategoricalAccuracy: 0.867 train_Precision: 0.980 train_Recall: 0.750 \n",
      "val_loss: 0.4947980046272278\n",
      "val_CategoricalAccuracy: 0.500 val_Precision: 0.000 val_Recall: 0.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 2 \n",
      "train_loss: 0.09012166410684586\n",
      "train_CategoricalAccuracy: 0.919 train_Precision: 0.969 train_Recall: 0.866 \n",
      "val_loss: 0.4997635781764984\n",
      "val_CategoricalAccuracy: 0.500 val_Precision: 0.000 val_Recall: 0.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 3 \n",
      "train_loss: 0.08510676771402359\n",
      "train_CategoricalAccuracy: 0.922 train_Precision: 0.965 train_Recall: 0.877 \n",
      "val_loss: 0.7746533751487732\n",
      "val_CategoricalAccuracy: 0.105 val_Precision: 0.167 val_Recall: 0.199 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 4 \n",
      "train_loss: 0.08188652247190475\n",
      "train_CategoricalAccuracy: 0.925 train_Precision: 0.956 train_Recall: 0.891 \n",
      "val_loss: 0.6516625881195068\n",
      "val_CategoricalAccuracy: 0.498 val_Precision: 0.499 val_Recall: 0.997 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 5 \n",
      "train_loss: 0.08610840141773224\n",
      "train_CategoricalAccuracy: 0.917 train_Precision: 0.967 train_Recall: 0.863 \n",
      "val_loss: 0.6464097499847412\n",
      "val_CategoricalAccuracy: 0.500 val_Precision: 0.500 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 6 \n",
      "train_loss: 0.08116349577903748\n",
      "train_CategoricalAccuracy: 0.930 train_Precision: 0.931 train_Recall: 0.928 \n",
      "val_loss: 0.5116980075836182\n",
      "val_CategoricalAccuracy: 0.500 val_Precision: 0.500 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 7 \n",
      "train_loss: 0.06980623304843903\n",
      "train_CategoricalAccuracy: 0.941 train_Precision: 0.968 train_Recall: 0.913 \n",
      "val_loss: 0.4503118693828583\n",
      "val_CategoricalAccuracy: 0.503 val_Precision: 0.501 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 8 \n",
      "train_loss: 0.06208636984229088\n",
      "train_CategoricalAccuracy: 0.950 train_Precision: 0.956 train_Recall: 0.943 \n",
      "val_loss: 0.4754942059516907\n",
      "val_CategoricalAccuracy: 0.502 val_Precision: 0.501 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 9 \n",
      "train_loss: 0.05827731266617775\n",
      "train_CategoricalAccuracy: 0.958 train_Precision: 0.950 train_Recall: 0.967 \n",
      "val_loss: 0.2757312059402466\n",
      "val_CategoricalAccuracy: 0.735 val_Precision: 0.653 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 10 \n",
      "train_loss: 0.058736227452754974\n",
      "train_CategoricalAccuracy: 0.946 train_Precision: 0.947 train_Recall: 0.945 \n",
      "val_loss: 0.09950476139783859\n",
      "val_CategoricalAccuracy: 0.900 val_Precision: 0.992 val_Recall: 0.807 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 11 \n",
      "train_loss: 0.06350834667682648\n",
      "train_CategoricalAccuracy: 0.945 train_Precision: 0.972 train_Recall: 0.916 \n",
      "val_loss: 0.11497879028320312\n",
      "val_CategoricalAccuracy: 0.941 val_Precision: 0.946 val_Recall: 0.936 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 12 \n",
      "train_loss: 0.04879295453429222\n",
      "train_CategoricalAccuracy: 0.962 train_Precision: 0.968 train_Recall: 0.956 \n",
      "val_loss: 0.09703774005174637\n",
      "val_CategoricalAccuracy: 0.949 val_Precision: 0.954 val_Recall: 0.943 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 13 \n",
      "train_loss: 0.038025423884391785\n",
      "train_CategoricalAccuracy: 0.972 train_Precision: 0.970 train_Recall: 0.974 \n",
      "val_loss: 0.1461784690618515\n",
      "val_CategoricalAccuracy: 0.918 val_Precision: 0.860 val_Recall: 0.999 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 14 \n",
      "train_loss: 0.033132098615169525\n",
      "train_CategoricalAccuracy: 0.976 train_Precision: 0.974 train_Recall: 0.978 \n",
      "val_loss: 0.33990809321403503\n",
      "val_CategoricalAccuracy: 0.645 val_Precision: 0.585 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 15 \n",
      "train_loss: 0.029391078278422356\n",
      "train_CategoricalAccuracy: 0.980 train_Precision: 0.978 train_Recall: 0.982 \n",
      "val_loss: 0.10593724250793457\n",
      "val_CategoricalAccuracy: 0.933 val_Precision: 0.882 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 16 \n",
      "train_loss: 0.027113767340779305\n",
      "train_CategoricalAccuracy: 0.981 train_Precision: 0.978 train_Recall: 0.984 \n",
      "val_loss: 0.08521211892366409\n",
      "val_CategoricalAccuracy: 0.955 val_Precision: 0.918 val_Recall: 0.999 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 17 \n",
      "train_loss: 0.025164462625980377\n",
      "train_CategoricalAccuracy: 0.984 train_Precision: 0.986 train_Recall: 0.981 \n",
      "val_loss: 0.05392904579639435\n",
      "val_CategoricalAccuracy: 0.958 val_Precision: 0.971 val_Recall: 0.944 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 18 \n",
      "train_loss: 0.02388147823512554\n",
      "train_CategoricalAccuracy: 0.985 train_Precision: 0.983 train_Recall: 0.986 \n",
      "val_loss: 0.054608967155218124\n",
      "val_CategoricalAccuracy: 0.960 val_Precision: 0.978 val_Recall: 0.941 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 19 \n",
      "train_loss: 0.021943964064121246\n",
      "train_CategoricalAccuracy: 0.985 train_Precision: 0.986 train_Recall: 0.985 \n",
      "val_loss: 0.10619432479143143\n",
      "val_CategoricalAccuracy: 0.930 val_Precision: 0.877 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n",
      "\n",
      "====================================================================================\n",
      "Epoch: 20 \n",
      "train_loss: 0.019465690478682518\n",
      "train_CategoricalAccuracy: 0.989 train_Precision: 0.987 train_Recall: 0.992 \n",
      "val_loss: 0.06727338582277298\n",
      "val_CategoricalAccuracy: 0.969 val_Precision: 0.942 val_Recall: 1.000 \n",
      "\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "resnet.train_loop(n_epochs=20, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training is done, we can close the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred sample duration of 4s\n",
      "Inferred input shape of (462, 150)\n",
      "INFO:tensorflow:Assets written to: tmp_export_folder\\model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kaitlin.palmer'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ketos.neural_networks.dev_utils.export import export_to_ketos_protobuf\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "\n",
    "\n",
    "# Loasd the audio repsentation\n",
    "spec_cfg = load_audio_representation('C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\KetosMinke\\\\Training Data\\\\CompletedModels\\\\20230524_01\\\\spec_configMinkeSpec.json', \n",
    "                                     name=\"spectrogram\")\n",
    "\n",
    "# Export to something PAMGuard can read\n",
    "export_to_ketos_protobuf(resnet,\n",
    "                         'C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\CompletedModels\\\\20230524_01\\\\MinkeBoing.ktpb',\n",
    "                         audio_repr=spec_cfg)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above will create the narw.kt file in the same directory where you are running this notebook (or the working directory for you session if you are running the python interpreter elsewhere). You can also specify a different folder and name, like ```resnet.save_model('trained_classifiers/my_classifier.kt')```.\n",
    "The ```audio_repr_file``` argument can be used to add an audio specification to the model file. This is useful when reusing the model because it makes the settings used to process the audio available within the model file. If this argument is omitted or set to ```None```, the settings will not be added to the model file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier works with 3 seconds long spectrograms as inputs.\n",
    "\n",
    "We won't actually use it directly, as our goal is to build a detector that will scan a longer .wav file (e.g.: 30min) and output time stamps for indicating when right whales are present. That's the topic of our [next step](https://docs.meridian.cs.dal.ca/ketos/tutorials/create_a_narw_detector/index.html), in which we will use the classifier we just trained to built our right whale detector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
