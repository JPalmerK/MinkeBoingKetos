{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a training database\n",
    "\n",
    "In this tutorial, we will use Ketos to create a database that can be used to train a deep learning classifier. \n",
    "\n",
    "We will use a subset of the data described in [Kirsebom et al. 2020](https://asa.scitation.org/doi/10.1121/10.0001132). These data consist of 3-s long clips, some containing right whale upcalls and others containing only background noise. The clips are wave files extracted from recordings produced by bottom-mounted hydrophones in the Gulf of Saint Lawrence, Canada.\n",
    "\n",
    "\n",
    "Our starting point will be a collection of .wav files accompanied by annotations. You can find them in the `data` folder within the .zip file linked at the top of this page. In the `train` folder, there are 2,000 files, half of them containing upcalls and the other half containing background noise (which, for our purpose, is any sound that is not an upcall. This includes sounds produced by other animals and the overall ambient noise). The `annotations_train.csv` file contains the label attributed to each file: 1 for upcall, 0 for background. Similarly, the `val` (validation) folder contains 200 .wav files (50% with upcalls) and is accompanied by the `annotations_val.csv` file.\n",
    "\n",
    "We will use Ketos to produce a database with spectrogram representations of the training and validation clips, so that we later can train a deep learning classifier to distinguish the upcalls from the other sounds. Eventually, we will use that classifier to build a detector.\n",
    "\n",
    "A different scenario would be where you have audio recordings and annotations indicating where in these recording the signals of interest are, but you don't have clips of uniform length with examples of the target signal(s) and background. That case is covered in [this tutorial](https://docs.meridian.cs.dal.ca/ketos/tutorials/create_database/index.html).\n",
    "\n",
    "We also encourage you to explore the [documentation](https://docs.meridian.cs.dal.ca/ketos/index.html), since Ketos has a variety of tools that might help you to build training databases in different scenarios.\n",
    "\n",
    "## Contents:\n",
    "\n",
    "[1. Importing the packages](#section1)  \n",
    "[2. Loading the annotations](#section2)  \n",
    "[3. Putting the annotations in the Ketos format](#section3)  \n",
    "[4. Choosing the spectrogram settings](#section4)  \n",
    "[5. Creating the database](#section5)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the packages\n",
    "For this tutorial we will use several modules within ketos. We will also the pandas to read our annotations files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ketos.data_handling import selection_table as sl\n",
    "import ketos.data_handling.database_interface as dbi\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "from ketos.audio.spectrogram import MagSpectrogram\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "import os\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir('C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\CompletedModels\\\\20230524_01')\n",
    "\n",
    "# test to see ketos loaded properly\n",
    "#help(load_audio_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the annotations\n",
    "Our annotations are saved in two `.csv` files: `annotations_train.csv` and `annotations_val.csv`, which we will use to create the training and validation datasets respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_train = pd.read_csv(\"C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\TP12khz\\\\TrainMinkeTrimmed.csv\")\n",
    "annot_val = pd.read_csv(\"C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\TP12khz\\\\ValMinkeTrimmed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARPsel.01.ch01.230523.191940.16..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARPsel.02.ch01.230523.191905.71..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARPsel.03.ch01.230523.191859.54..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARPsel.04.ch01.230523.191752.56..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HARPsel.06.ch01.230523.191847.88..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>Augment_2812_SWAPS-042597-NS62a.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>Augment_2813_SWAPS-042597-NS62b.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>Augment_2814_SWAPS-042597-NS63.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>Augment_2816_SWAPS-042597-NS65.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>Augment_2817_SWAPS-042697-NS66.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6010 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sound_file  label\n",
       "0     HARPsel.01.ch01.230523.191940.16..wav      0\n",
       "1     HARPsel.02.ch01.230523.191905.71..wav      0\n",
       "2     HARPsel.03.ch01.230523.191859.54..wav      0\n",
       "3     HARPsel.04.ch01.230523.191752.56..wav      0\n",
       "4     HARPsel.06.ch01.230523.191847.88..wav      0\n",
       "...                                     ...    ...\n",
       "6005    Augment_2812_SWAPS-042597-NS62a.wav      1\n",
       "6006    Augment_2813_SWAPS-042597-NS62b.wav      1\n",
       "6007     Augment_2814_SWAPS-042597-NS63.wav      1\n",
       "6008     Augment_2816_SWAPS-042597-NS65.wav      1\n",
       "6009     Augment_2817_SWAPS-042697-NS66.wav      1\n",
       "\n",
       "[6010 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARPsel.05.ch01.230523.191819.59..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARPsel.10.ch01.230523.191441.97..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARPsel.104.ch01.230523.184731.43..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARPsel.109.ch01.230523.184916.73..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HARPsel.113.ch01.230523.184540.07..wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Augment_2795_SWAPS-042197-NS48.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Augment_2800_SWAPS-042197-NS52.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Augment_2805_SWAPS-042297-NS56b.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Augment_2810_SWAPS-042297-NS60b.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Augment_2815_SWAPS-042597-NS64.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1501 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sound_file  label\n",
       "0      HARPsel.05.ch01.230523.191819.59..wav      0\n",
       "1      HARPsel.10.ch01.230523.191441.97..wav      0\n",
       "2     HARPsel.104.ch01.230523.184731.43..wav      0\n",
       "3     HARPsel.109.ch01.230523.184916.73..wav      0\n",
       "4     HARPsel.113.ch01.230523.184540.07..wav      0\n",
       "...                                      ...    ...\n",
       "1496      Augment_2795_SWAPS-042197-NS48.wav      1\n",
       "1497      Augment_2800_SWAPS-042197-NS52.wav      1\n",
       "1498     Augment_2805_SWAPS-042297-NS56b.wav      1\n",
       "1499     Augment_2810_SWAPS-042297-NS60b.wav      1\n",
       "1500      Augment_2815_SWAPS-042597-NS64.wav      1\n",
       "\n",
       "[1501 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **annot_train** dataframe contains 2000 rows and the **annot_val** 200.\n",
    "The columns indicate:\n",
    "\n",
    "**sound_file:** name of the audio file  \n",
    "**label:** label for the annotation (1 for upcall, 0 for background))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Putting the annotations in the Ketos format\n",
    "Let's check if our annotations follow the Ketos standard.\n",
    "\n",
    "If that's the case, the function ```sl.is_standardized``` will return ```True```. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Your table is not in the Ketos format.\n",
      "\n",
      "            It should have two levels of indices: filename and annot_id.\n",
      "            It should also contain at least the 'label' column.\n",
      "            If your annotations have time information, these should appear in the 'start' and 'end' columns\n",
      "\n",
      "            extra columns are allowed.\n",
      "\n",
      "            Here is a minimum example:\n",
      "\n",
      "                                 label\n",
      "            filename  annot_id                    \n",
      "            file1.wav 0          2\n",
      "                      1          1\n",
      "                      2          2\n",
      "            file2.wav 0          2\n",
      "                      1          2\n",
      "                      2          1\n",
      "\n",
      "\n",
      "            And here is a table with time information and a few extra columns ('min_freq', 'max_freq' and 'file_time_stamp')\n",
      "\n",
      "                                 start   end  label  min_freq  max_freq  file_time_stamp\n",
      "            filename  annot_id                    \n",
      "            file1.wav 0           7.0   8.1      2    180.6     294.3    2019-02-24 13:15:00\n",
      "                      1           8.5  12.5      1    174.2     258.7    2019-02-24 13:15:00\n",
      "                      2          13.1  14.0      2    183.4     292.3    2019-02-24 13:15:00\n",
      "            file2.wav 0           2.2   3.1      2    148.8     286.6    2019-02-24 13:30:00\n",
      "                      1           5.8   6.8      2    156.6     278.3    2019-02-24 13:30:00\n",
      "                      2           9.0  13.0      1    178.2     304.5    2019-02-24 13:30:00\n",
      "\n",
      "    \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.is_standardized(annot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Your table is not in the Ketos format.\n",
      "\n",
      "            It should have two levels of indices: filename and annot_id.\n",
      "            It should also contain at least the 'label' column.\n",
      "            If your annotations have time information, these should appear in the 'start' and 'end' columns\n",
      "\n",
      "            extra columns are allowed.\n",
      "\n",
      "            Here is a minimum example:\n",
      "\n",
      "                                 label\n",
      "            filename  annot_id                    \n",
      "            file1.wav 0          2\n",
      "                      1          1\n",
      "                      2          2\n",
      "            file2.wav 0          2\n",
      "                      1          2\n",
      "                      2          1\n",
      "\n",
      "\n",
      "            And here is a table with time information and a few extra columns ('min_freq', 'max_freq' and 'file_time_stamp')\n",
      "\n",
      "                                 start   end  label  min_freq  max_freq  file_time_stamp\n",
      "            filename  annot_id                    \n",
      "            file1.wav 0           7.0   8.1      2    180.6     294.3    2019-02-24 13:15:00\n",
      "                      1           8.5  12.5      1    174.2     258.7    2019-02-24 13:15:00\n",
      "                      2          13.1  14.0      2    183.4     292.3    2019-02-24 13:15:00\n",
      "            file2.wav 0           2.2   3.1      2    148.8     286.6    2019-02-24 13:30:00\n",
      "                      1           5.8   6.8      2    156.6     278.3    2019-02-24 13:30:00\n",
      "                      2           9.0  13.0      1    178.2     304.5    2019-02-24 13:30:00\n",
      "\n",
      "    \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.is_standardized(annot_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of our annotations are in the format ketos expects. But we can use the ```sl.standardize``` function to convert to the specified format.\n",
    "\n",
    "The *annot_id* column is created automatically by the ```sl.standardize``` function. From the remaining required columns indicated in the example above, we already have *start*, *end* and *label*. Our *sound_file* column needs to be renamed to *filename*, so we will need to provide a dictionary to specify that. \n",
    "\n",
    "We have one extra column, *datetime*, that we don't really need to keep, so we'll set ```trim_table=True```, which will exclude any columns that are not required by the standardized tables.\n",
    "\n",
    "If we wanted to keep the datetime (or any other columns), we would just set ```trim_table=False```. One situation in which you might to do that is if you need this information to split a dataset in train/test or train/validation/test, because then you can sort all your annotations by time and make sure the training set does not overlap with the validation/test. But in our case, the annotations are already split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_ketos_annot_std ={'filename': 'sound_file'} \n",
    "std_annot_train = sl.standardize(table=annot_train, mapper=map_to_ketos_annot_std,trim_table=True)\n",
    "std_annot_val = sl.standardize(table=annot_val, mapper=map_to_ketos_annot_std, trim_table=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our standardized tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th>annot_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Augment_1001_sel.14.ch01.230603.022928.50..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1002_sel.140.ch01.230529.014235.17..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1003_sel.141.ch01.230529.014629.32..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1004_sel.15.ch01.230520.081352.56..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1006_sel.15.ch01.230520.214758.68..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.85.ch01.230520.143234.70..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.87.ch01.230520.143308.25..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.88.ch01.230520.143309.25..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.89.ch01.230520.143338.00..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.90.ch01.230520.143339.00..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6010 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          label\n",
       "filename                                        annot_id       \n",
       "Augment_1001_sel.14.ch01.230603.022928.50..wav  0             1\n",
       "Augment_1002_sel.140.ch01.230529.014235.17..wav 0             1\n",
       "Augment_1003_sel.141.ch01.230529.014629.32..wav 0             1\n",
       "Augment_1004_sel.15.ch01.230520.081352.56..wav  0             1\n",
       "Augment_1006_sel.15.ch01.230520.214758.68..wav  0             1\n",
       "...                                                         ...\n",
       "sel.85.ch01.230520.143234.70..wav               0             1\n",
       "sel.87.ch01.230520.143308.25..wav               0             1\n",
       "sel.88.ch01.230520.143309.25..wav               0             1\n",
       "sel.89.ch01.230520.143338.00..wav               0             1\n",
       "sel.90.ch01.230520.143339.00..wav               0             1\n",
       "\n",
       "[6010 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_annot_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section8></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th>annot_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Augment_1000_sel.14.ch01.230522.171913.45..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1005_sel.15.ch01.230520.141655.26..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_100_sel.181.ch01.230529.015612.62..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1010_sel.16.ch01.230520.081353.56..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augment_1015_sel.161.ch01.230529.015203.11..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.64.ch01.230520.215722.19..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.70.ch01.230520.142901.19..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.75.ch01.230520.143015.15..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.81.ch01.230520.143123.85..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sel.86.ch01.230520.143235.70..wav</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1501 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          label\n",
       "filename                                        annot_id       \n",
       "Augment_1000_sel.14.ch01.230522.171913.45..wav  0             1\n",
       "Augment_1005_sel.15.ch01.230520.141655.26..wav  0             1\n",
       "Augment_100_sel.181.ch01.230529.015612.62..wav  0             1\n",
       "Augment_1010_sel.16.ch01.230520.081353.56..wav  0             1\n",
       "Augment_1015_sel.161.ch01.230529.015203.11..wav 0             1\n",
       "...                                                         ...\n",
       "sel.64.ch01.230520.215722.19..wav               0             1\n",
       "sel.70.ch01.230520.142901.19..wav               0             1\n",
       "sel.75.ch01.230520.143015.15..wav               0             1\n",
       "sel.81.ch01.230520.143123.85..wav               0             1\n",
       "sel.86.ch01.230520.143235.70..wav               0             1\n",
       "\n",
       "[1501 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_annot_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.is_standardized(std_annot_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Choosing the spectrogram settings\n",
    "\n",
    "As mentioned earlier, we'll represent the segments as spectrograms.\n",
    "In the .zip file where you found the data, there's also a spectrogram configuration file (```spec_config.json```) which contains the settings we want to use.\n",
    "\n",
    "This configuration file is simply a text file in the ```.json``` format, so you could make a copy of it, change a few parameters and save several settings to use later or to share the with someone else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cfg = load_audio_representation('spec_configMinkeSpec.json', name=\"spectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rate': 12000,\n",
       " 'window': 0.0853,\n",
       " 'step': 0.00853,\n",
       " 'freq_min': 750,\n",
       " 'freq_max': 2500,\n",
       " 'window_func': 'hamming',\n",
       " 'type': ketos.audio.spectrogram.MagSpectrogram,\n",
       " 'duration': 4}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a python dictionary. We could change some value, like the step size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec_cfg['step'] = 0.064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we will stick to the original here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creating the databaseÂ¶\n",
    "Now, we have to c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section8></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating the database\n",
    "\n",
    "Now, we have to compute the spectrograms following the settings above for each selection in our selection tables (i.e.: each 3s clip) and then save them in a database.\n",
    "\n",
    "All of this can be done with the ```dbi.create_database``` function in Ketos.\n",
    "\n",
    "We will start with the training dataset. We need to indicate the name for the database we want to create, where the audio files are, a name for the dataset, the selections table and the audio representation. As specified in our ``spec_cfg``, this is a Magnitude spectrogram, but ketos can also create databases with Power, Mel and CQT spectrograms, as well as time-domain data (waveforms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6010 [00:00<?, ?it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 459 samples were padded on the left and 612 samples were padded on the right\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6010/6010 [03:00<00:00, 33.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6010 items saved to databaseMinkeTrimmed01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dbi.create_database(output_file='databaseMinkeTrimmed01.h5', \n",
    "                    data_dir='C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\TP12khz\\\\TrainTrim',\n",
    "                               dataset_name='train',\n",
    "                    selections=std_annot_train,\n",
    "                               audio_repres=spec_cfg)\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do the same thing for the validation set. Note that, by specifying the same database name, we are telling ketos that we want to add the validation set to the existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1501/1501 [00:44<00:00, 33.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501 items saved to databaseMinkeTrimmed01.h5\n"
     ]
    }
   ],
   "source": [
    "dbi.create_database(output_file='databaseMinkeTrimmed01.h5', \n",
    "                    data_dir='C:\\\\Users\\\\kaitlin.palmer\\\\Desktop\\\\KetosMinke\\\\Training Data\\\\TP12khz\\\\ValTrim',\n",
    "                               dataset_name='val',\n",
    "                    selections=std_annot_val,\n",
    "                               audio_repres=spec_cfg)\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our database with spectrograms representing audio segments with and without the North Atlantic Right Whale upcall. The data is divided into 'train' and 'validation'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dbi.open_file(\"databaseMinkeTrimmed01.h5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=databaseMinkeTrimmed01.h5, title='', mode='r', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/train (Group) ''\n",
       "/train/data (Table(6010,)fletcher32, shuffle, zlib(1)) ''\n",
       "  description := {\n",
       "  \"data\": Float32Col(shape=(462, 150), dflt=0.0, pos=0),\n",
       "  \"filename\": StringCol(itemsize=100, shape=(), dflt=b'', pos=1),\n",
       "  \"id\": UInt32Col(shape=(), dflt=0, pos=2),\n",
       "  \"label\": UInt8Col(shape=(), dflt=0, pos=3),\n",
       "  \"offset\": Float64Col(shape=(), dflt=0.0, pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1,)\n",
       "/val (Group) ''\n",
       "/val/data (Table(1501,)fletcher32, shuffle, zlib(1)) ''\n",
       "  description := {\n",
       "  \"data\": Float32Col(shape=(462, 150), dflt=0.0, pos=0),\n",
       "  \"filename\": StringCol(itemsize=100, shape=(), dflt=b'', pos=1),\n",
       "  \"id\": UInt32Col(shape=(), dflt=0, pos=2),\n",
       "  \"label\": UInt8Col(shape=(), dflt=0, pos=3),\n",
       "  \"offset\": Float64Col(shape=(), dflt=0.0, pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()  #Close the database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the data divided into 'train' and 'validation'. These are called 'groups' in HDF5 terms. Within each of them there is a dataset called 'data', which contains the spectrograms and respective labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely not need to directly interact with the database. In a following tutorial, we will use Ketos to build a deep neural network and train it to recognize upcalls. Ketos handles the database interactions, so we won't really have to go into the details of it, but if you would like to learn more about how to get data from this database, take a look at the [database_interface](https://docs.meridian.cs.dal.ca/ketos/modules/data_handling/database_interface.html) module in ketos and the [pyTables](https://www.pytables.org/index.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1001a4970b29c28621d582a03dc3fa0b89a0dfeec536d3482b741039182f0b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
